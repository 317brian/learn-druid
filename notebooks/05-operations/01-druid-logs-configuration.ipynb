{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9fc0614-4eec-4c39-ad22-ea10afa00e9d",
   "metadata": {},
   "source": [
    "# Apache Druid and Log4j\n",
    "\n",
    "Apache Druid uses Log4J to emit information as it runs. They not only enable you to investigate issues and solve problems, but to understand how each of Druid's processes work in isolation and in collaboration with one another.\n",
    "\n",
    "In this learning module we will:\n",
    "\n",
    "* Identify the various Druid process log files.\n",
    "* Understand the role of the log files.\n",
    "* Review some task log files.\n",
    "\n",
    "The first step in making use of log files is to become aware of what logs are available. We'll see that the Druid processes each generate a couple of different files. In addition to the process log files, we will see that transient Druid worker tasks also generate log files.\n",
    "\n",
    "Apache Druid has a microservices architecture, enabling scale and resilience. Logs are an essential source of information when troubleshooting and monitoring a cluster.\n",
    "\n",
    "As Druid processes run, they write status information into files called log files. We can use these files to understand the Druid processes' behaviors and diagnose problems.\n",
    "\n",
    "\n",
    "\n",
    "Some processes may spin off tasks to perform sub-processing. In Druid, a task is separate process that usually runs in its own JVM. Each of these tasks create their own log files.\n",
    "\n",
    "Many of the logs capture behavior during ingestion and other processing, but we can also configure Druid to capture specific query information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9a55db-61ff-4fa4-9655-2fef292ed2aa",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "This tutorial works with Druid 28.0.1 or later.\n",
    "\n",
    "### Run with Docker\n",
    "\n",
    "Launch this tutorial and all prerequisites using the `jupyter` profile of the Docker Compose file for Jupyter-based Druid tutorials. For more information, see the Learn Druid repository [readme](https://github.com/implydata/learn-druid)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ede96-348f-423c-adc7-0e23c6910b9e",
   "metadata": {},
   "source": [
    "## Initialization\n",
    "\n",
    "To use this notebook, you will need to run Druid locally.\n",
    "\n",
    "You will also make extensive use of the terminal, which we suggest you place alongside this notebook or on another screen.\n",
    "\n",
    "### Install tools\n",
    "\n",
    "Open a local terminal window.\n",
    "\n",
    "If you have not already install `wget` or `multitail`, run the following commands to install these tools using `brew`.\n",
    "\n",
    "```bash\n",
    "brew install multitail && brew install wget\n",
    "```\n",
    "\n",
    "Run the following command to pull the default configuration for `multitail` to your home folder. Do not run this command if you are already running `multitail` as it will overwrite your own configuration.\n",
    "\n",
    "```bash\n",
    "curl https://raw.githubusercontent.com/halturin/multitail/master/multitail.conf > ~/.multitailrc\n",
    "```\n",
    "\n",
    "### Install Apache Druid\n",
    "\n",
    "Run the following to create a dedicated folder for learn-druid in your home directory:\n",
    "\n",
    "```bash\n",
    "cd && mkdir learn-druid-local\n",
    "cd learn-druid-local\n",
    "```\n",
    "\n",
    "Now pull a compatible version of Druid.\n",
    "\n",
    "> If you do not have wget on your Mac, you can install it with brew.\n",
    "\n",
    "```bash\n",
    "wget https://dlcdn.apache.org/druid/28.0.1/apache-druid-28.0.1-bin.tar.gz && tar -xzf apache-druid-28.0.1-bin.tar.gz &&\n",
    "cd apache-druid-28.0.1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d07feb7-92dd-42a9-ad6c-c89d5fdad8d5",
   "metadata": {},
   "source": [
    "# Review the log file configuration\n",
    "\n",
    "The log file configuration is set in the `log4j2.xml` alongside Druid's own configuration files.\n",
    "\n",
    "Remembering that Druid has multiple configuration file locations out-of-the-box, run this command to view the `auto` configuration file for logs that's used by the `learn-druid` script:\n",
    "\n",
    "```bash\n",
    "more ~/learn-druid-local/apache-druid-28.0.1/conf/druid/auto/_common/log4j2.xml\n",
    "```\n",
    "\n",
    "On the first page, within the [`Configuration`](https://logging.apache.org/log4j/log4j-2.4/manual/configuration.html#ConfigurationSyntax) you will see:\n",
    "\n",
    "* [`Properties`](https://logging.apache.org/log4j/2.x/manual/configuration.html#PropertySubstitution) provide key/values pairs that may be used throughout the configuration file.\n",
    "* [`Appenders`](https://logging.apache.org/log4j/2.x/manual/appenders.html) designate the format of log messages and determine the target for the messages.\n",
    "\n",
    "Further along you will see:\n",
    "\n",
    "* [`Loggers`](https://logging.apache.org/log4j/2.x/manual/configuration.html#Loggers) filter the log messages and dispense them to Appenders. Loggers can filter messages based on the Java package and/or class and by message priority.\n",
    "\n",
    "The default Configuration for Druid does not include a [`monitorInterval`](https://logging.apache.org/log4j/log4j-2.4/manual/configuration.html#AutomaticReconfiguration) property, so changes to logging configuration are only recognised when a process restarts.\n",
    "\n",
    "For the purposes of this tutorial, run the following command to add a `monitorInterval` property to the Configuration.\n",
    "\n",
    "```bash\n",
    "sed -i '' 's/<Configuration status=\"WARN\">/<Configuration status=\"WARN\" monitorInterval=\"5\">/' \\\n",
    "  ~/learn-druid-local/apache-druid-28.0.1/conf/druid/auto/_common/log4j2.xml\n",
    "```\n",
    "Now start Druid with the following command, and remember to take a note of the process Id reported after the command has run:\n",
    "\n",
    "```bash\n",
    "nohup bin/start-druid > log.out 2> log.err < /dev/null & disown\n",
    "```\n",
    "\n",
    "__It's important that you remember this process ID for later in the tutorial.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca62693b-50f4-4831-a092-dbc8e06d8191",
   "metadata": {},
   "source": [
    "## Properties\n",
    "\n",
    "In Druid, `Properties` are leveraged to set a location for all logs. This location is calculated when Druid stars, and passed as a parameter to Java and on to Log4J for each process.\n",
    "\n",
    "> IS THE ABOVE CORRECT?\n",
    "\n",
    "By default, this location is a \"log\" folder at the root of your Druid installation, but [can be over-ridden]((https://druid.apache.org/docs/latest/configuration/logging#log-directory) by using the `DRUID_LOG_DIR` system variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec19737-2773-4c66-a05e-d0b1a707c4c8",
   "metadata": {},
   "source": [
    "## Appenders\n",
    "\n",
    "There are two `appenders`:\n",
    "\n",
    "* A [`Console`](https://logging.apache.org/log4j/log4j-2.4/manual/appenders.html#ConsoleAppender) appender called \"Console\" for `SYSTEM_OUT`.\n",
    "* A [`RollingRandomAccessFile`](https://logging.apache.org/log4j/log4j-2.4/manual/appenders.html#RollingRandomAccessFileAppender) appender called \"FileAppender\" which is used for detailed process logs.\n",
    "\n",
    "The \"FileAppender\" `RollingRandomAccessFile` appender has `fileName` and `filePattern` properties. These control the initial and on-going file names.\n",
    "\n",
    "Run the following command to see switch to the default location for the log files.\n",
    "\n",
    "```bash\n",
    "cd ~/learn-druid-local/apache-druid-28.0.1/log\n",
    "```\n",
    "\n",
    "Since Druid is a distributed system, we will find log files for each Druid process. In addition, Druid also captures the output written to the standard output.\n",
    "\n",
    "Use the following command to take a look at what is here:\n",
    "```bash\n",
    "ls\n",
    "```\n",
    "\n",
    "You can see how this results in two sets of files being created:\n",
    "\n",
    "* `process name.stdout.log` file - which is the information written by the processes to stdout (i.e., the terminal)\n",
    "* `process name.log` - file containing various status, error, warning and debug messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5258912e-bf23-4acd-9267-a7f4ea3bc6f4",
   "metadata": {},
   "source": [
    "### Log filenames\n",
    "\n",
    "The `fileName` property of the \"FileAppender\" sets the name of the log file being written to at the moment, while `filePattern` is applied when the log rolls over.\n",
    "\n",
    "Run the following command to change the default filename in the log4j configuration file:\n",
    "\n",
    "```bash\n",
    "sed -i '' 's/{sys:druid.node.type}.log/{sys:druid.node.type}-mycluster.log/' \\\n",
    "  ~/learn-druid-local/apache-druid-28.0.1/conf/druid/auto/_common/log4j2.xml\n",
    "```\n",
    "\n",
    "List the contents of the log folder again to see the changes:\n",
    "\n",
    "```bash\n",
    "ls\n",
    "```\n",
    "\n",
    "Revert the change with the following command:\n",
    "\n",
    "```bash\n",
    "sed -i '' 's/{sys:druid.node.type}-mycluster.log/{sys:druid.node.type}.log/' \\\n",
    "  ~/learn-druid-local/apache-druid-28.0.1/conf/druid/auto/_common/log4j2.xml\n",
    "```\n",
    "\n",
    "Since \"FileAppender\" is a [RollingRandomAccessFileAppender](https://logging.apache.org/log4j/log4j-2.4/manual/appenders.html#RollingRandomAccessFileAppender) you can adjust the `TimeBasedTriggeringPolicy` to change when `fileName` log files are rolled over to `filePattern` log files.\n",
    "\n",
    "Run the following in your terminal to adjust the `filePattern` to include the hours and minutes.\n",
    "\n",
    "```bash\n",
    "sed -i '' 's/{yyyyMMdd}/{yyyyMMdd-HH:mm}/' \\\n",
    "  ~/learn-druid-local/apache-druid-28.0.1/conf/druid/auto/_common/log4j2.xml\n",
    "```\n",
    "\n",
    "Since the `TimeBasedTriggeringPolicy` is set to 1 by default, a change in the least granular element of the `filePattern` will trigger a rollover. In this case, you will now see a new file being created every minute.\n",
    "\n",
    "```bash\n",
    "ls\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2f17b3-f359-4df8-a682-7398e7d2adf8",
   "metadata": {},
   "source": [
    "### Log retention\n",
    "\n",
    "Since \"FileAppender\" is a [RollingRandomAccessFileAppender](https://logging.apache.org/log4j/log4j-2.4/manual/appenders.html#RollingRandomAccessFileAppender) you can adjust the `DefaultRolloverStrategy` to control retention of logs by adjusting the `Delete` section.\n",
    "\n",
    "`IfFileName` and `IfLastModified` are used in conjunction to remove any files from the log folder that match the rules. The default is to remove matching files older than two months, based on the date last modified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab489e-aa10-4482-a62d-3c106bdb06cc",
   "metadata": {},
   "source": [
    "### Log patterns\n",
    "\n",
    "The content of log files is specified in the `PatternLayout`.\n",
    "\n",
    "```\n",
    "`%d{ISO8601} %p [%t] %c -%notEmpty{ [%markerSimpleName]} %m%n`\n",
    "```\n",
    "\n",
    "* Timestamp (`%d{ISO8601}`)\n",
    "* Message priority (`%p`)\n",
    "* Thread name (`[%t]`)\n",
    "* Class name (`%c`)\n",
    "* Message (`%m%n`)\n",
    "\n",
    "Run this command to see this information from two of the process logs:\n",
    "\n",
    "```bash\n",
    "multitail --config multitail.conf -CS log4jnew -du -P a \\\n",
    "    -f coordinator-overlord.log\n",
    "```\n",
    "\n",
    "Threads and classes are helpful for diagnosis, especially for WARN and ERROR conditions, while messages describe what has happened, what the state of the process or some significant variable is. These serve not just for diagnosis but for general learning of how the Druid database works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e8716-621c-4c94-90f2-360f568629d1",
   "metadata": {},
   "source": [
    "## Loggers\n",
    "\n",
    "This section of the configuration controls what types of events are logged and what data as recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8e5519-88d7-4da1-982d-c8ba6fe4e83c",
   "metadata": {},
   "source": [
    "### Logging level\n",
    "\n",
    "Developers assign different log levels to different entries, indicating how severe an event is.\n",
    "\n",
    "* FATAL (system failure)\n",
    "* ERROR (functional failure)\n",
    "* WARN (non-fatal issue)\n",
    "* INFO (notable event)\n",
    "* DEBUG (program debugging messages)\n",
    "* TRACE (highly granular execution event)\n",
    "\n",
    "The default configuration sets a `Root` level for the `FileAppender` of `INFO`, meaning that only messages with a level of `INFO` and above will be recorded.\n",
    "\n",
    "```xml\n",
    "    <Root level=\"info\">\n",
    "        <AppenderRef ref=\"FileAppender\"/>\n",
    "    </Root>\n",
    "```\n",
    "\n",
    "Other base levels are set at a class level, reducing log noise. For example:\n",
    "\n",
    "```xml\n",
    "    <!-- Quieter KafkaSupervisors -->\n",
    "    <Logger name=\"org.apache.kafka.clients.consumer.internals\" level=\"warn\" additivity=\"false\">\n",
    "        <Appender-ref ref=\"FileAppender\"/>\n",
    "    </Logger>\n",
    "```\n",
    "\n",
    "Run this command to amend the base logging level for all Druid processes:\n",
    "\n",
    "```bash\n",
    "sed -i '' 's/Root level=\"info\"/Root level=\"debug\"/' \\\n",
    "  ~/learn-druid-local/apache-druid-28.0.1/conf/druid/auto/_common/log4j2.xml\n",
    "```\n",
    "\n",
    "Watch the change in information on the multitail window.\n",
    "\n",
    "Revert the logging level to INFO before proceeding.\n",
    "\n",
    "```bash\n",
    "sed -i '' 's/Root level=\"debug\"/Root level=\"info\"/' \\\n",
    "  ~/learn-druid-local/apache-druid-28.0.1/conf/druid/auto/_common/log4j2.xml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0a46b8-77f4-4792-9484-9acba0407b3d",
   "metadata": {},
   "source": [
    "## Using the logs\n",
    "\n",
    "Two recommended approaches for working with log files are:\n",
    "\n",
    "1. Search individual log files for indications of a problem, such as WARN, ERROR, and FATAL, and of Java exceptions in stack traces (e.g. `java.net.ConnectionException: Connection refused`.\n",
    "2. Read log files more like a novel, starting at the beginning of the file - or some known intermediate point - and then follow the story logically.\n",
    "\n",
    "In approach 1, it's possible to work back through the history, using the time field as a key. You may notice large time gaps, or use filtering to remove any events from threads or classes that you know are not relevant to the error.\n",
    "\n",
    "Approach 2 requires more time, but helps to solve more complex problems. It's also an important learning aid when delving deep into how Druid's processes collaborate to realise services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c081295-750e-41a3-9693-7fe50af401fa",
   "metadata": {},
   "source": [
    "### Useful searches in logs\n",
    "\n",
    "| Log | Search Term |\n",
    "|---|---|\n",
    "| Any | __NodeRoleWatcher__<br>Across all the processes, watch as they detect changes in the processes that are running in the cluster, and see what they do about it! |\n",
    "| Coordinator / Overlord | __org.apache.druid.metadata.SQLMetadataRuleManager__<br>This is the coordinator polling the rules in the metadata database, getting ready to apply them. The log tells you how many rules it picks up and how many data sources they cover. |\n",
    "| Coordinator / Overlord | __org.apache.druid.metadata.SqlSegmentsMetadataManager__<br>Messages show how many segments the cluster thinks are “used” – ready to be used for queries. |\n",
    "| Coordinator / Overlord | __org.apache.druid.indexing.overlord.RemoteTaskRunner__<br>GIves interesting information about what’s happening with ingestion resources in the cluster, including when they first advertise themselves. |\n",
    "| Coordinator / Overlord | __org.apache.druid.server.coordinator.rules__<br>Lots of information about how the retention rules are actually being applied (or not!). |\n",
    "| Historical | __org.apache.druid.server.coordination.BatchDataSegmentAnnouncer__<br>You can see individual segments being announced as available for query by each historical server as it loads them. |\n",
    "| Historical | __org.apache.druid.server.coordination.SegmentLoadDropHandler__<br>As well as seeing how the historical checks its local segment cache on startup, you can watch along as the Historical picks up the instructions from the coordinator and then does something about them. When there are ERRORs like “Failed to load segment for dataSource” you get traces about what the process was trying to do – quite often something pointing to an error with its connection to deep storage. |\n",
    "| Any | __org.apache.druid.initialization.Initialization__<br>These messages are all about the process starting up. It can be interesting to see what exactly each one does – and if it runs into issues. |\n",
    "| Coordinator | __org.apache.druid.server.coordinator.duty.BalanceSegments__<br>Here you can see what Druid decides to do when balancing needs to be carried out – e.g. a server is lost or added. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9137fc3-9f53-4887-a2b2-b8cabb061cc5",
   "metadata": {},
   "source": [
    "### Example: failure in Apache Zookeeper\n",
    "\n",
    "Druid's process rely on [Apache Zookeeper](https://zookeeper.apache.org/) for [inter-process communication and configuration](https://druid.apache.org/docs/latest/dependencies/zookeeper.html). Run the following command to simulate a failure in Zookeeper.\n",
    "\n",
    "The first of these two commands prevents Zookeeper from being recovered by the `learn-druid` script's `supervisor`, and the second then kills the Zookerper process.\n",
    "\n",
    "```bash\n",
    "kill -STOP $(ps -ef | grep 'perl' | awk 'NF{print $2}' | head -n 1)\n",
    "kill $(ps -ef | grep 'zoo' | awk 'NF{print $2}' | head -n 1)\n",
    "```\n",
    "\n",
    "Lets see how this appears in the logs:\n",
    "\n",
    "```bash\n",
    "multitail -CS log4jnew -du -P a -s 2 -sn 2,2 \\\n",
    "    -f coordinator-overlord.log \\\n",
    "    -f broker.log \\\n",
    "    -f middlemanager.log \\\n",
    "    -f historical.log\n",
    "```\n",
    "\n",
    "Run the command below to have Zookeeper restart.\n",
    "\n",
    "```bash\n",
    "kill -CONT $(ps -ef | grep 'perl' | awk 'NF{print $2}' | head -n 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1023e5a3-cedc-435f-a448-30f8c3ae1535",
   "metadata": {},
   "source": [
    "# Stop Druid\n",
    "\n",
    "Run this command to stop Druid, replacing \"{pid}\" with the process Id you noted earlier.\n",
    "\n",
    "```bash\n",
    "kill {pid}\n",
    "```\n",
    "\n",
    "For example:\n",
    "\n",
    "```bash\n",
    "kill 9864\n",
    "```\n",
    "\n",
    "> If you do not remember your PID, use `ps` to look for the `supervise` process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5921b-636e-4a85-ae4d-dc0239bfef0b",
   "metadata": {},
   "source": [
    "## Learn more\n",
    "\n",
    "In the lab you learned that you can turn on logging for query requests with the druid.startup.logging.logProperties setting. Read all the options - including other possible targets for these logs - in the documentation. An interesting configuration, for example, automatically filters query logging for you.\n",
    "\n",
    "Watch this Druid Summit presentation by Amir Youssefi and Pawas Ranjan from Conviva that describes how useful this information can be to tuning Druid clusters.\n",
    "\n",
    "* [Druid optimizations for scaling customer facing analytics at Conviva](https://youtu.be/zkHXr-3GFJw?t=746)\n",
    "\n",
    "Take a few minutes to scan the official documentation for information about logging configuration. You may want to keep this page to hand throughout the course.\n",
    "\n",
    "* [Logging](https://druid.apache.org/docs/latest/configuration/logging.html)\n",
    "\n",
    "You're about to learn more about Apache Druid's use of Apache Logging Services in the form of Log4J™. Get insight into the background and benefits of Log4J on the official project website:\n",
    "\n",
    "* [Apache Logging Services](https://logging.apache.org/)\n",
    "* Read your options for `filePattern`s by refering to the [simple date format](https://docs.oracle.com/javase/7/docs/api/java/text/SimpleDateFormat.html) documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
